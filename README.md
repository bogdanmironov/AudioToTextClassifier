# Audio-to-Text Classification System

A system for recognizing spoken input and classifying it into tasks, reminders, notes, and events.

## Overview

This project implements an end-to-end pipeline for converting audio recordings into text and classifying the resulting text into four categories:

- Task  
- Reminder  
- Note  
- Event  

The goal is to streamline personal organization: when a user verbally describes something they need to remember or do, the system automatically transcribes the audio, interprets the intent, and classifies it. This enables automated population of calendars, task managers, or note applications.

The system combines speech recognition, text preprocessing, machine learning classification, and a server interface that accepts audio uploads and returns predictions.

---

## 1. Speech Recognition

The system uses Automatic Speech Recognition (ASR) to convert audio into text.  
ASR is powered by **Whisper AI**, a transformer-based speech recognition model.

Other commonly used ASR tools include:

- Speechnotes  
- Dictation  
- Talktyper  
- Voxsci  
- Whisper  

After transcription, the resulting text is passed to the classifier.

---

## 2. Text Vectorization Techniques

Before classification, text must be converted into numerical vectors.  
This project uses standard text vectorization approaches, including:

### 1. Bag of Words (BoW)
Represents text as a vector of token occurrences.

### 2. TF-IDF
Adjusts word importance based on its frequency across documents.

### 3. Word Embeddings (Word2Vec, GloVe)
Learns dense vector representations that capture semantic meaning.

### 4. Transformer-Based Embeddings (BERT, GPT)
Contextual representations generated by deep transformer models.

These methods are used inside the Python ML training pipeline.

---

## 3. System Architecture

The system consists of several major components:

- **Data Extraction**  
  Loading datasets from CSV, JSON, Parquet, or online repositories.

- **Preprocessing**  
  Normalizing, cleaning, and labeling text data from multiple datasets.

- **Model Training**  
  Training a text classification model to predict one of the four categories.

- **Evaluation**  
  Measuring accuracy, analyzing confusion matrices, and balancing datasets.

- **Server Integration**  
  A Flask server combines Whisper and the classifier so that users can upload `.mp4` audio files and receive a predicted category.

---

## 4. Datasets Used

Multiple datasets were combined to achieve wide coverage of user intents:

### TOPv2 Dataset (Semantic Parsing)
- 180,000+ labeled examples across 8 domains.  
- Used for event and reminder classification.

### MS-LaTTE Dataset (Microsoft Tasks)
- 10,101 real-world task entries.  
- Used for task classification.

### Whatâ€™s Happening LA Calendar Dataset
- Real event listings from Los Angeles.  
- Used for event classification.

### Blog Authorship Corpus
- 681,288 blog posts from 19,320 authors.  
- Used for note classification.

These datasets were merged and preprocessed into a unified classification corpus.


## 5. Model perfomance

- **Accuracy:** 0.9764960826804467

- **Confusion Matrix:**
  
[[1453   34    3   10]

 [   3 1472    2   22]
 
 [   0    3 1495    2]
 
 [  12   47    3 1438]]
- **F1-score:** 0.98
